{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 5: Transfer learning model with denoised images and augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model utilizes transfer learning and the functional Keras API to produce a mixed convolutional model on denoised images. Because of imbalance, the melanoma images are augmented. A dropout layer and L2 regularization were included to prevent overfitting. The model utilizes the [Xception](https://keras.io/api/applications/xception/) architecture, trained on the famous [ImageNet](https://image-net.org/) image database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Input, Model\n",
    "from tensorflow.keras.applications import Xception\n",
    "from tensorflow.keras.layers import Concatenate, Conv2D, Dense, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.metrics import AUC, Recall\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.metrics import classification_report\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "import time\n",
    "\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age_approx</th>\n",
       "      <th>Unknown</th>\n",
       "      <th>female</th>\n",
       "      <th>male</th>\n",
       "      <th>head/neck</th>\n",
       "      <th>lower extremity</th>\n",
       "      <th>oral/genital</th>\n",
       "      <th>palms/soles</th>\n",
       "      <th>torso</th>\n",
       "      <th>upper extremity</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>45.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>55.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age_approx  Unknown  female  male  head/neck  lower extremity  \\\n",
       "0        45.0        0       0     1          1                0   \n",
       "1        45.0        0       1     0          0                0   \n",
       "2        50.0        0       1     0          0                1   \n",
       "3        45.0        0       1     0          1                0   \n",
       "4        55.0        0       1     0          0                0   \n",
       "\n",
       "   oral/genital  palms/soles  torso  upper extremity  target  \n",
       "0             0            0      0                0       0  \n",
       "1             0            0      0                1       0  \n",
       "2             0            0      0                0       0  \n",
       "3             0            0      0                0       0  \n",
       "4             0            0      0                1       0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta = pd.read_csv('../processed_data/train.csv', index_col=0)\n",
    "meta.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = meta['target'].values.reshape(-1,1)\n",
    "X = meta.drop('target', axis=1)\n",
    "meta_train, meta_test, y_train, y_test = train_test_split(X, y, test_size=0.3 ,random_state=867_5309, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_train = meta_train.astype('ushort')\n",
    "meta_test = meta_test.astype('ushort')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23188, 10)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23188, 1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '../processed_data/processed_train_img_array.pkl'\n",
    "with open(PATH, 'rb') as file:\n",
    "    img_array = pickle.load(file)\n",
    "img_array = img_array.astype('ushort')\n",
    "img_train, img_test, _1, _2 = train_test_split(img_array, y, test_size=0.3, stratify=y, random_state=867_5309) # Should split exactly the same as above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23188, 80, 120, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9938, 80, 120, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Prepare augmentation files\n",
    "augmentation_files = pd.read_csv('../data/train.csv', usecols=['image_name'])\n",
    "augmentation_files = pd.concat([augmentation_files,meta], axis=1)\n",
    "augmentation_files = augmentation_files[augmentation_files['target'] == 1]\n",
    "augmentation_files['index'] = range(len(augmentation_files))\n",
    "\n",
    "raw_files_path = '../data/jpeg/train/'\n",
    "augmentation_files['image_name'] = augmentation_files['image_name'].map(lambda x: raw_files_path+x+'.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate data generator\n",
    "aug = ImageDataGenerator(rotation_range=270,\n",
    "                        height_shift_range=0.1,\n",
    "                        width_shift_range=0.1,\n",
    "                        brightness_range=[0.3,0.9],\n",
    "                        channel_shift_range=50.0,\n",
    "                        horizontal_flip=True,\n",
    "                        vertical_flip=True,\n",
    "                        shear_range=25.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 584 validated image filenames.\n",
      "Batch 1 completed.\n",
      "Batch 2 completed.\n",
      "Batch 3 completed.\n",
      "Batch 4 completed.\n",
      "Batch 5 completed.\n",
      "Batch 6 completed.\n",
      "Batch 7 completed.\n",
      "Batch 8 completed.\n",
      "Batch 9 completed.\n",
      "Batch 10 completed.\n",
      "Batch 11 completed.\n",
      "Batch 12 completed.\n",
      "Batch 13 completed.\n",
      "Batch 14 completed.\n",
      "Batch 15 completed.\n",
      "Batch 16 completed.\n",
      "Batch 17 completed.\n",
      "Batch 18 completed.\n",
      "Batch 19 completed.\n",
      "Batch 20 completed.\n",
      "Batch 21 completed.\n",
      "Batch 22 completed.\n",
      "Batch 23 completed.\n",
      "Batch 24 completed.\n",
      "Batch 25 completed.\n",
      "Batch 26 completed.\n",
      "Batch 27 completed.\n",
      "Batch 28 completed.\n",
      "Batch 29 completed.\n",
      "Batch 30 completed.\n",
      "Batch 31 completed.\n",
      "Batch 32 completed.\n",
      "Batch 33 completed.\n",
      "Batch 34 completed.\n",
      "Batch 35 completed.\n",
      "Batch 36 completed.\n",
      "Batch 37 completed.\n",
      "Batch 38 completed.\n",
      "Batch 39 completed.\n"
     ]
    }
   ],
   "source": [
    "ITERATIONS = img_train.shape[0]//len(augmentation_files)\n",
    "aug.fit(img_train)\n",
    "img_generator = aug.flow_from_dataframe(dataframe=augmentation_files,\n",
    "                                        x_col='image_name',\n",
    "                                        y_col='index',\n",
    "                                        class_mode='raw',\n",
    "                                        shuffle=False,\n",
    "                                        target_size=img_train.shape[1:3],\n",
    "                                        seed=867_5309\n",
    "                                       )\n",
    "\n",
    "# Augment data additional \n",
    "img_y = np.empty((1,1))\n",
    "iteration = 0\n",
    "for x_batch in img_generator:\n",
    "    iteration += 1\n",
    "    img_train = np.concatenate((img_train, x_batch[0]), axis=0)\n",
    "    img_y = np.concatenate((img_y, x_batch[1].reshape(-1,1)), axis=0)\n",
    "    print(f'Batch {iteration} completed.')\n",
    "    if iteration == ITERATIONS:\n",
    "        break\n",
    "img_y = img_y[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join metadata\n",
    "new_metadata = pd.DataFrame(img_y, columns=['index']).astype('int')\n",
    "new_metadata = pd.merge(new_metadata,augmentation_files,\n",
    "                        on='index',\n",
    "                        how='left',\n",
    "                        validate='many_to_many')[meta.columns]\n",
    "\n",
    "meta_train = pd.concat([meta_train, new_metadata.drop('target', axis=1)])\n",
    "y_train = np.concatenate([y_train, new_metadata['target'].values.reshape(-1,1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 80, 120, 3)] 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "xception (Functional)           (None, 3, 4, 2048)   20861480    input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 10)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 3, 4, 8)      409608      xception[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 4)            44          input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 8)            0           conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 4)            20          dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 8)            0           global_average_pooling2d[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 12)           0           dense_1[0][0]                    \n",
      "                                                                 dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 4)            52          concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1)            5           dense_2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 21,271,209\n",
      "Trainable params: 21,216,681\n",
      "Non-trainable params: 54,528\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "LEARNING_RATE = 0.001\n",
    "recall = Recall(name='recall')\n",
    "\n",
    "# Define inputs\n",
    "meta_inputs = Input(shape=(10,))\n",
    "img_inputs = Input(shape=(80,120,3,))\n",
    "\n",
    "# Model 1\n",
    "meta_model = Dense(4, activation='relu')(meta_inputs)\n",
    "meta_model = Dense(4, activation='relu')(meta_model)\n",
    "\n",
    "# Model 2\n",
    "img_model = Xception(include_top=False, input_shape=(80,120,3,))(img_inputs)\n",
    "img_model = Conv2D(8, kernel_size=(5,5),\n",
    "                         padding='same',\n",
    "                         activation='relu')(img_model)\n",
    "img_model = GlobalAveragePooling2D()(img_model)\n",
    "img_model = Dropout(rate=0.35)(img_model)\n",
    "\n",
    "# Merge models\n",
    "merged_model = Concatenate()([meta_model, img_model])\n",
    "merged_model = Dense(4, activation='relu',\n",
    "                     kernel_regularizer=l2(l=0.04))(merged_model)\n",
    "merged_output = Dense(1, activation='sigmoid')(merged_model)\n",
    "\n",
    "\n",
    "# Define functional model\n",
    "model = Model(inputs=[meta_inputs, img_inputs], outputs=merged_output)\n",
    "\n",
    "# Compile model\n",
    "auc = AUC(name = 'auc')\n",
    "model.compile(Adam(learning_rate=LEARNING_RATE), loss='binary_crossentropy', metrics=[auc, recall])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See `fchollet`'s discussion of class weights [here](https://keras.io/examples/structured_data/imbalanced_classification/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 1.070635234206945, 1: 15.157240522063391}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_for_0 = 1.0 / ((len(y_train)-y_train.sum())/len(y_train))\n",
    "weight_for_1 = 1.0 / (y_train.sum()/len(y_train))\n",
    "class_weight = {0: weight_for_0, 1: weight_for_1}\n",
    "class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 50\n",
    "BATCH_SIZE = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "2439/2439 [==============================] - 153s 59ms/step - loss: 1.3960 - auc: 0.6450 - recall: 0.7028 - val_loss: 0.6069 - val_auc: 0.7762 - val_recall: 0.7486\n",
      "Epoch 2/50\n",
      "2439/2439 [==============================] - 145s 59ms/step - loss: 1.1033 - auc: 0.7946 - recall: 0.7999 - val_loss: 0.6155 - val_auc: 0.5717 - val_recall: 0.1429\n",
      "Epoch 3/50\n",
      "2439/2439 [==============================] - 145s 60ms/step - loss: 1.1501 - auc: 0.7688 - recall: 0.6119 - val_loss: 0.5048 - val_auc: 0.7072 - val_recall: 0.2743\n",
      "Epoch 4/50\n",
      "2439/2439 [==============================] - 147s 60ms/step - loss: 1.1215 - auc: 0.7913 - recall: 0.6412 - val_loss: 0.3981 - val_auc: 0.7370 - val_recall: 0.4000\n",
      "Epoch 5/50\n",
      "2439/2439 [==============================] - 146s 60ms/step - loss: 1.1295 - auc: 0.7658 - recall: 0.8299 - val_loss: 0.3949 - val_auc: 0.7461 - val_recall: 0.7086\n",
      "Epoch 6/50\n",
      "2439/2439 [==============================] - 146s 60ms/step - loss: 1.1306 - auc: 0.7460 - recall: 0.8668 - val_loss: 0.4632 - val_auc: 0.6937 - val_recall: 0.5429\n",
      "Epoch 7/50\n",
      "2439/2439 [==============================] - 146s 60ms/step - loss: 1.0926 - auc: 0.7770 - recall: 0.8705 - val_loss: 0.3717 - val_auc: 0.7472 - val_recall: 0.5429\n",
      "Epoch 8/50\n",
      "2439/2439 [==============================] - 146s 60ms/step - loss: 1.0886 - auc: 0.7942 - recall: 0.8279 - val_loss: 0.7972 - val_auc: 0.6848 - val_recall: 0.8914\n",
      "Epoch 9/50\n",
      "2439/2439 [==============================] - 146s 60ms/step - loss: 1.0383 - auc: 0.8210 - recall: 0.8119 - val_loss: 0.4759 - val_auc: 0.7750 - val_recall: 0.7143\n",
      "Epoch 10/50\n",
      "2439/2439 [==============================] - 147s 60ms/step - loss: 1.0522 - auc: 0.8205 - recall: 0.8327 - val_loss: 0.4756 - val_auc: 0.7761 - val_recall: 0.7771\n",
      "Epoch 11/50\n",
      "2439/2439 [==============================] - 146s 60ms/step - loss: 1.0703 - auc: 0.7920 - recall: 0.8461 - val_loss: 0.5678 - val_auc: 0.7378 - val_recall: 0.8000\n",
      "Epoch 12/50\n",
      "2439/2439 [==============================] - 146s 60ms/step - loss: 1.0561 - auc: 0.7869 - recall: 0.8376 - val_loss: 0.5480 - val_auc: 0.7567 - val_recall: 0.7429\n",
      "Epoch 13/50\n",
      "2439/2439 [==============================] - 147s 60ms/step - loss: 1.0290 - auc: 0.8083 - recall: 0.8310 - val_loss: 0.4340 - val_auc: 0.7914 - val_recall: 0.6743\n",
      "Epoch 14/50\n",
      "2439/2439 [==============================] - 147s 60ms/step - loss: 1.0507 - auc: 0.8086 - recall: 0.8129 - val_loss: 0.7178 - val_auc: 0.6848 - val_recall: 0.7657\n",
      "Epoch 15/50\n",
      "2439/2439 [==============================] - 146s 60ms/step - loss: 1.0471 - auc: 0.8154 - recall: 0.8133 - val_loss: 0.4498 - val_auc: 0.7871 - val_recall: 0.7143\n",
      "Epoch 16/50\n",
      "2439/2439 [==============================] - 147s 60ms/step - loss: 0.9994 - auc: 0.8293 - recall: 0.8501 - val_loss: 0.5566 - val_auc: 0.7634 - val_recall: 0.8343\n",
      "Epoch 17/50\n",
      "2439/2439 [==============================] - 147s 60ms/step - loss: 1.0775 - auc: 0.7898 - recall: 0.8483 - val_loss: 0.4915 - val_auc: 0.7784 - val_recall: 0.7086\n",
      "Epoch 18/50\n",
      "2439/2439 [==============================] - 147s 60ms/step - loss: 0.9915 - auc: 0.8348 - recall: 0.8378 - val_loss: 0.4322 - val_auc: 0.7757 - val_recall: 0.6571\n",
      "Epoch 19/50\n",
      "2439/2439 [==============================] - 147s 60ms/step - loss: 1.0162 - auc: 0.8264 - recall: 0.8178 - val_loss: 0.4789 - val_auc: 0.7777 - val_recall: 0.7200\n",
      "Epoch 20/50\n",
      "2439/2439 [==============================] - 148s 61ms/step - loss: 1.0208 - auc: 0.8273 - recall: 0.8053 - val_loss: 0.5642 - val_auc: 0.7635 - val_recall: 0.8400\n",
      "Epoch 21/50\n",
      "2439/2439 [==============================] - 147s 60ms/step - loss: 1.0256 - auc: 0.8096 - recall: 0.8293 - val_loss: 0.4989 - val_auc: 0.7929 - val_recall: 0.7200\n",
      "Epoch 22/50\n",
      "2063/2439 [========================>.....] - ETA: 20s - loss: 0.9744 - auc: 0.8361 - recall: 0.8540"
     ]
    }
   ],
   "source": [
    "# for reproducibility, we will set a seed\n",
    "np.random.seed(1)\n",
    "tf.random.set_seed(2)\n",
    "\n",
    "history = model.fit(x = [meta_train, img_train], y = y_train,\n",
    "                    class_weight=class_weight,\n",
    "                    epochs = EPOCHS,\n",
    "                    batch_size = BATCH_SIZE,\n",
    "                    validation_data=([meta_test, img_test], y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.arange(0, EPOCHS)\n",
    "\n",
    "plt.figure(1, figsize = (20, 12))\n",
    "plt.subplot(1,2,1)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.plot(X, history.history['loss'], label = 'Training Loss')\n",
    "plt.plot(X, history.history['val_loss'], label = 'Validation Loss')\n",
    "plt.grid(True)\n",
    "plt.xticks(X+1)\n",
    "plt.legend()\n",
    "plt.title('Loss', fontsize=30)\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('AUC')\n",
    "plt.plot(X, history.history['auc'], label = 'Training AUC')\n",
    "plt.plot(X, history.history['val_auc'], label = 'Validation AUC')\n",
    "plt.grid(True)\n",
    "plt.xticks(X+1)\n",
    "plt.legend()\n",
    "_ = plt.title('AUC', fontsize=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict([meta_test, img_test])\n",
    "y_pred = np.array([int(i) for i in y_pred > 0.5])\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
