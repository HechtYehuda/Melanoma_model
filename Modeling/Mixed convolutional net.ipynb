{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import models, layers\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = pd.read_csv('../processed_data/train.csv', index_col=0)\n",
    "meta.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = meta['target']\n",
    "X = meta.drop('target', axis=1)\n",
    "meta_train, meta_test, y_train, y_test = train_test_split(X, y, test_size=0.3 ,random_state=867_5309)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_train = meta_train.astype('ushort')\n",
    "meta_test = meta_test.astype('ushort')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PATH = '../processed_data/train_img_array.pkl'\n",
    "TEST_PATH = '../processed_data/test_img_array.pkl'\n",
    "with open(TRAIN_PATH, 'rb') as file:\n",
    "    img_train = pickle.load(file)\n",
    "with open(TEST_PATH, 'rb') as file:\n",
    "    img_test = pickle.load(file)\n",
    "img_train = img_train.astype('ushort')\n",
    "img_test = img_test.astype('ushort')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model with utilize the functional Keras API to produce a mixed model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define inputs\n",
    "meta_inputs = tf.keras.Input(shape=(2065,))\n",
    "img_inputs = tf.keras.Input(shape=(80,120,3,))\n",
    "\n",
    "# Model 1\n",
    "meta_layer1 = tf.keras.layers.Dense(64, activation='relu')(meta_inputs)\n",
    "meta_output_layer = tf.keras.layers.Dense(1, activation='sigmoid')(meta_layer1)\n",
    "\n",
    "# Model 2\n",
    "img_conv_layer1 = tf.keras.layers.Conv2D(32, kernel_size=(3,3), padding='same', activation='relu')(img_inputs)\n",
    "img_pooling_layer1 = tf.keras.layers.MaxPooling2D()(img_conv_layer1)\n",
    "img_conv_layer2 = tf.keras.layers.Conv2D(64, kernel_size=(3,3), padding='same', activation='relu')(img_pooling_layer1)\n",
    "img_pooling_layer2 = tf.keras.layers.MaxPooling2D()(img_conv_layer2)\n",
    "img_flatten_layer = tf.keras.layers.Flatten()(img_pooling_layer2)\n",
    "img_dense_layer = tf.keras.layers.Dense(1024, activation='relu')(img_flatten_layer)\n",
    "img_output_layer = tf.keras.layers.Dense(1, activation='sigmoid')(img_dense_layer)\n",
    "\n",
    "# Merge models\n",
    "merged = tf.keras.layers.add([meta_output_layer, img_output_layer])\n",
    "\n",
    "# Define functional model\n",
    "model = tf.keras.Model(inputs=[meta_inputs, img_inputs], outputs=merged)\n",
    "\n",
    "# Compile model\n",
    "auc = tf.keras.metrics.AUC(name = 'auc')\n",
    "model.compile('adam', loss='binary_crossentropy', metrics=[auc])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 15\n",
    "history = model.fit(meta_X_train, meta_y_train, epochs=epochs, batch_size=15_000, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.arange(0, epochs)\n",
    "plt.figure(1, figsize = (20, 12))\n",
    "plt.subplot(1,2,1)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.plot(X, history.history['loss'], label = 'Training Loss')\n",
    "plt.plot(X, history.history['val_loss'], label = 'Validation Loss')\n",
    "plt.grid(True)\n",
    "plt.xticks(X)\n",
    "plt.legend()\n",
    "plt.title('Loss', fontsize=30)\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.plot(X, history.history['auc'], label = 'Training AUC')\n",
    "plt.plot(X, history.history['val_auc'], label = 'Validation AUC')\n",
    "plt.grid(True)\n",
    "plt.xticks(X)\n",
    "plt.legend()\n",
    "plt.title('AUC', fontsize=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
